# GuÃ­a Completa de Agentes - Transfer Learning Pipeline

## ğŸ¯ Resumen del Sistema

El sistema implementa **transfer learning escalonado** donde cada agente aprende una tarea especÃ­fica y transfiere su conocimiento al siguiente:

```
Madera â†’ Piedra â†’ Hierro â†’ Diamante â†’ Desde Cero (Completo)
```

---

## ğŸ“Š Stage 1: Wood Agent (Agente de Madera)

**Archivo**: `madera/wood_agent.py`

### Objetivo
Recolectar **3 logs** y craftear un **wooden pickaxe**

### Inventario Inicial
- Manos vacÃ­as (puede romper wood directamente)

### CondiciÃ³n de TÃ©rmino
- âœ… **Ã‰xito**: Tiene `wooden_pickaxe` en inventario
- â±ï¸ **Timeout**: 6000 pasos

### Modelo Guardado
- **UbicaciÃ³n**: `entrenamiento_acumulado/{algorithm}_model.pkl`
- **Ejemplos**: `qlearning_model.pkl`, `sarsa_model.pkl`, etc.

### CSV Generado
- **UbicaciÃ³n**: `madera/metrics_data/{algorithm}_WoodAgent_{timestamp}.csv`
- **Columnas**: Episode, Steps, WoodCollected, TotalReward, AvgReward, Epsilon, Actions

### Recompensas
- `+1000` por cada log recolectado
- `+10000` por craftear wooden pickaxe (Ã©xito)
- `-100` por acciÃ³n inÃºtil (moverse sin propÃ³sito)

---

## ğŸ“Š Stage 2: Stone Agent (Agente de Piedra)

**Archivo**: `piedra/stone_agent.py`

### Objetivo
Recolectar **3 cobblestone** y craftear un **stone pickaxe**

### Inventario Inicial
- `wooden_pickaxe` (para minar cobblestone)
- `sticks` (necesarios para craftear)
- `planks` (para craftear sticks si se necesitan)

### CondiciÃ³n de TÃ©rmino
- âœ… **Ã‰xito**: Tiene `stone_pickaxe` en inventario
- â±ï¸ **Timeout**: 6000 pasos

### Modelo Cargado (Transfer Learning)
- **Desde**: `entrenamiento_acumulado/{algorithm}_model.pkl` (Stage 1)
- **Ejemplo**: Carga `qlearning_model.pkl` si el algoritmo es Q-Learning

### Modelo Guardado
- **UbicaciÃ³n**: `entrenamiento_acumulado/{algorithm}_stone_model.pkl`
- **Contenido**: Q-table de Stage 1 + aprendizaje de Stage 2

### CSV Generado
- **UbicaciÃ³n**: `piedra/metrics_data/{algorithm}_StoneAgent_{timestamp}.csv`

### Recompensas
- `+1000` por cada cobblestone recolectado
- `+10000` por craftear stone pickaxe (Ã©xito)
- `-100` por acciÃ³n inÃºtil

---

## ğŸ“Š Stage 3: Iron Agent (Agente de Hierro)

**Archivo**: `hierro/iron_agent.py`

### Objetivo
Recolectar **3 iron ingots** y craftear un **iron pickaxe**

### Inventario Inicial
- `stone_pickaxe` (para minar iron_ore â†’ iron_block)
- `sticks` (para craftear)
- `planks` (backup para sticks)

### SimplificaciÃ³n Implementada
- `iron_block` dropea `iron_ingot` directamente (sin necesidad de furnace)

### CondiciÃ³n de TÃ©rmino
- âœ… **Ã‰xito**: Tiene `iron_pickaxe` en inventario
- â±ï¸ **Timeout**: 6000 pasos

### Modelo Cargado (Transfer Learning)
- **Desde**: `entrenamiento_acumulado/{algorithm}_stone_model.pkl` (Stage 2)
- **Contenido**: Conocimiento acumulado de Stage 1 + Stage 2

### Modelo Guardado
- **UbicaciÃ³n**: `entrenamiento_acumulado/{algorithm}_iron_model.pkl`
- **Contenido**: Q-table de Stage 1 + Stage 2 + Stage 3

### CSV Generado
- **UbicaciÃ³n**: `hierro/metrics_data/{algorithm}_IronAgent_{timestamp}.csv`

### Recompensas
- `+1000` por cada iron_ingot recolectado
- `+10000` por craftear iron pickaxe (Ã©xito)
- `-100` por acciÃ³n inÃºtil

---

## ğŸ“Š Stage 4: Diamond Agent (Agente de Diamante)

**Archivo**: `diamante/diamond_agent.py`

### Objetivo
Recolectar **diamantes** (cantidad no fija, maximizar)

### Inventario Inicial
- `iron_pickaxe` (necesario para minar diamond_ore)

### CondiciÃ³n de TÃ©rmino
- âœ… **Ã‰xito**: Tiene al menos `1 diamond` en inventario
- â±ï¸ **Timeout**: 6000 pasos

### Modelo Cargado (Transfer Learning)
- **Desde**: `entrenamiento_acumulado/{algorithm}_iron_model.pkl` (Stage 3)
- **Contenido**: Conocimiento acumulado de Stage 1 + Stage 2 + Stage 3

### Modelo Guardado
- **UbicaciÃ³n**: `entrenamiento_acumulado/{algorithm}_diamond_model.pkl`
- **Contenido**: Q-table completa de todos los stages hasta aquÃ­

### CSV Generado
- **UbicaciÃ³n**: `diamante/metrics_data/{algorithm}_DiamondAgent_{timestamp}.csv`

### Recompensas
- `+1000` por cada diamond recolectado
- `+10000` si recolecta al menos 1 diamond (Ã©xito)
- `-100` por acciÃ³n inÃºtil

---

## ğŸ“Š Stage 5: From Scratch Agent (Desde Cero - Completo)

**Archivo**: `desde_cero/from_scratch_agent.py`

### Objetivo Completo
Completar el **tech tree completo** desde cero:
1. Recolectar 3 wood â†’ Craftear wooden pickaxe
2. Recolectar 3 cobblestone â†’ Craftear stone pickaxe
3. Recolectar 3 iron â†’ Craftear iron pickaxe
4. Recolectar diamantes

### Inventario Inicial
- `diamond_axe` (para optimizar recolecciÃ³n de wood)

### CondiciÃ³n de TÃ©rmino
- âœ… **Ã‰xito**: Tiene `iron_pickaxe` Y al menos `1 diamond`
- â±ï¸ **Timeout**: 6000 pasos

### Modelo Cargado (Transfer Learning)
- **Desde**: `entrenamiento_acumulado/{algorithm}_diamond_model.pkl` (Stage 4)
- **Contenido**: **TODO** el conocimiento acumulado de los 4 stages anteriores

### Modelo Guardado
- **UbicaciÃ³n**: `entrenamiento_acumulado/{algorithm}_scratch_model.pkl`
- **Contenido**: **MODELO FINAL** - Q-table con todo el aprendizaje del pipeline

### CSV Generado
- **UbicaciÃ³n**: `desde_cero/metrics_data/{algorithm}_FromScratchAgent_{timestamp}.csv`

### Recompensas
- `+1000` por cada material recolectado (wood, stone, iron, diamond)
- `+10000` por cada pickaxe crafteado
- `+50000` por completar todo el tech tree
- `-100` por acciÃ³n inÃºtil

---

## ğŸ”„ Pipeline de Transfer Learning

### Flujo de Entrenamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: WOOD                                              â”‚
â”‚  Entrena: 50 episodios                                      â”‚
â”‚  Guarda: qlearning_model.pkl                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: STONE                                             â”‚
â”‚  Carga: qlearning_model.pkl                                 â”‚
â”‚  Entrena: 50 episodios (continÃºa desde Stage 1)            â”‚
â”‚  Guarda: qlearning_stone_model.pkl                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: IRON                                              â”‚
â”‚  Carga: qlearning_stone_model.pkl                           â”‚
â”‚  Entrena: 50 episodios (continÃºa desde Stage 1+2)          â”‚
â”‚  Guarda: qlearning_iron_model.pkl                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: DIAMOND                                           â”‚
â”‚  Carga: qlearning_iron_model.pkl                            â”‚
â”‚  Entrena: 50 episodios (continÃºa desde Stage 1+2+3)        â”‚
â”‚  Guarda: qlearning_diamond_model.pkl                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: FROM SCRATCH (COMPLETO)                           â”‚
â”‚  Carga: qlearning_diamond_model.pkl                         â”‚
â”‚  Entrena: 50 episodios (todo el conocimiento acumulado)    â”‚
â”‚  Guarda: qlearning_scratch_model.pkl â† MODELO FINAL         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comando de Entrenamiento

```bash
# Entrenar pipeline completo con transfer learning
python train_parallel_pipeline.py --episodes 50 --continuar si

# Entrenar solo stages 1-3
python train_parallel_pipeline.py --episodes 50 --inicio 1 --final 3

# Entrenar desde cero sin transfer learning
python train_parallel_pipeline.py --episodes 50 --continuar no
```

---

## ğŸ“ Estructura de Archivos Generados

```
3_entrega/
â”œâ”€â”€ entrenamiento_acumulado/
â”‚   â”œâ”€â”€ qlearning_model.pkl              â† Stage 1
â”‚   â”œâ”€â”€ qlearning_stone_model.pkl        â† Stage 1+2
â”‚   â”œâ”€â”€ qlearning_iron_model.pkl         â† Stage 1+2+3
â”‚   â”œâ”€â”€ qlearning_diamond_model.pkl      â† Stage 1+2+3+4
â”‚   â”œâ”€â”€ qlearning_scratch_model.pkl      â† FINAL (todos los stages)
â”‚   â”œâ”€â”€ sarsa_model.pkl
â”‚   â”œâ”€â”€ sarsa_stone_model.pkl
â”‚   â””â”€â”€ ... (mismo patrÃ³n para cada algoritmo)
â”‚
â”œâ”€â”€ madera/
â”‚   â””â”€â”€ metrics_data/
â”‚       â”œâ”€â”€ qlearning_WoodAgent_1763954849.csv
â”‚       â”œâ”€â”€ qlearning_WoodAgent_1763954849.png
â”‚       â””â”€â”€ ... (6 algoritmos Ã— 2 archivos)
â”‚
â”œâ”€â”€ piedra/
â”‚   â””â”€â”€ metrics_data/
â”‚       â”œâ”€â”€ qlearning_StoneAgent_1763955000.csv
â”‚       â””â”€â”€ ... 
â”‚
â”œâ”€â”€ hierro/
â”‚   â””â”€â”€ metrics_data/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ diamante/
â”‚   â””â”€â”€ metrics_data/
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ desde_cero/
    â””â”€â”€ metrics_data/
        â””â”€â”€ ...
```

---

## âš™ï¸ ParÃ¡metros de ConfiguraciÃ³n

### Todos los Agentes Comparten

```python
# Dimensiones del mundo
radio = 10  # Radio del Ã¡rea de generaciÃ³n

# LÃ­mites de pasos
max_steps = 6000

# GeneraciÃ³n de bloques
wood: ~8-12 bloques
cobblestone: ~8-12 bloques  
iron_block: ~8-12 bloques
diamond_ore: ~8-12 bloques

# Seed fijo
env_seed = 123456  # Mismo layout de bloques en todos los episodios
```

### Algoritmos Soportados

1. **Q-Learning** - Puerto 10001
2. **SARSA** - Puerto 10002
3. **Expected SARSA** - Puerto 10003
4. **Double Q-Learning** - Puerto 10004
5. **Monte Carlo** - Puerto 10005
6. **Random** (baseline) - Puerto 10006

---

## ğŸ› Troubleshooting

### Problema: "Modelo no existe"
**Causa**: El stage anterior no guardÃ³ el modelo
**SoluciÃ³n**: Ejecutar el stage anterior primero o usar `--continuar no`

### Problema: "Episode no termina"
**Causa**: El agente alcanzÃ³ max_steps sin completar objetivo
**SoluciÃ³n**: Normal en entrenamiento temprano, mejora con mÃ¡s episodios

### Problema: "CSV no se genera"
**Causa**: Error en MetricsLogger o permisos de escritura
**SoluciÃ³n**: Verificar que `metrics_data/` existe y tiene permisos

### Problema: "Puerto ocupado"
**Causa**: Minecraft no estÃ¡ corriendo en ese puerto
**SoluciÃ³n**: Abrir 6 clientes de Minecraft en puertos 10001-10006

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### MÃ©tricas Clave

- **Steps**: Menor es mejor (mÃ¡s eficiente)
- **TotalReward**: Mayor es mejor
- **AvgReward**: Eficiencia por paso
- **Epsilon**: Disminuye con episodios (menos exploraciÃ³n)
- **Success**: Porcentaje de episodios exitosos

### Esperado con Transfer Learning

- Stage 2 deberÃ­a completarse mÃ¡s rÃ¡pido que Stage 1 entrenado desde cero
- Stage 3 mÃ¡s rÃ¡pido que Stage 2
- Stage 4 y 5 se benefician de todo el conocimiento acumulado

---

## âœ… Checklist de EjecuciÃ³n

Antes de entrenar:
- [ ] 6 clientes de Minecraft abiertos (puertos 10001-10006)
- [ ] Carpeta `entrenamiento_acumulado/` existe
- [ ] Carpetas `metrics_data/` en cada stage
- [ ] MALMO_DIR configurado correctamente

Durante entrenamiento:
- [ ] Verificar que CSV se va actualizando
- [ ] Verificar que .pkl se guarda despuÃ©s de cada episodio
- [ ] Monitorear que episodes terminan (no se quedan esperando)

DespuÃ©s de entrenar:
- [ ] Revisar CSV generados en cada `metrics_data/`
- [ ] Verificar PNG con grÃ¡ficas
- [ ] Confirmar que modelos .pkl existen en `entrenamiento_acumulado/`
- [ ] Ejecutar `analyze_results.py` en cada carpeta para comparar algoritmos
