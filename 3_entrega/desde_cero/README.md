# From Scratch Agent - Stage 5 (Complete Pipeline)

## Descripci√≥n General
**Quinta y √∫ltima etapa** del entrenamiento jer√°rquico. El agente demuestra que el transfer learning funciona completando **TODO EL TECH TREE** desde casi cero (solo diamond_axe inicial).

## Inventario Inicial
El agente comienza **CASI VAC√çO**:
- **Slot 0**: `diamond_axe` (1) ‚Üê Solo para recolectar wood

**¬°El agente debe obtener TODO lo dem√°s!**

## Objetivo
Completar **TODAS las etapas del tech tree**:

### üéØ Tech Tree Completo
1. **Stage 1**: Recolectar 3 wood ‚Üí Craftear wooden_pickaxe
2. **Stage 2**: Recolectar 3 stone ‚Üí Craftear stone_pickaxe
3. **Stage 3**: Recolectar 3 iron ore ‚Üí Craftear iron_pickaxe
4. **Stage 4**: Recolectar 1 diamond ‚Üê **OBJETIVO FINAL**

### Condiciones de Terminaci√≥n
- ‚úÖ **√âxito**: El agente recolecta 1 diamante (completando todas las etapas previas)
- ‚è±Ô∏è **Timeout**: 300 segundos (5 minutos) ‚Üê **M√ÅS TIEMPO** que otras etapas

## Mundo/Entorno
- **Tipo**: Flat world con TODOS los recursos
- **Dimensiones**: 21x21 (x: -10 a 10, z: -10 a 10)
- **Spawn**: (0.5, 4, 0.5)
- **Piso**: Obsidian (y=3, indestructible)
- **Paredes**: Obsidian perimetral (y=4 a y=6)
- **Bloques generados**:
  - **Diamond ore**: 3-5 bloques (MUY RARO) en y=4
  - **Iron ore**: ~20 bloques en y=4-5
  - **Stone**: ~25 bloques en y=4-5
  - **Wood (log)**: ~20 bloques en y=4-5

**Este es el mundo m√°s completo con todos los recursos disponibles.**

## Caracter√≠sticas T√©cnicas

### Espacio de Estados
**10 elementos** (id√©ntico a diamond_agent):
1. `surroundings` (tuple): Grid 5x5x3 del entorno
2. `wood_count` (int): Cantidad de wood/log
3. `stone_count` (int): Cantidad de stone
4. `iron_count` (int): Cantidad de iron_ore/iron_ingot
5. `diamond_count` (int): Cantidad de diamond
6. `planks_count` (int): Cantidad de planks
7. `sticks_count` (int): Cantidad de sticks
8. `has_wooden_pickaxe` (bool): Tiene pico de madera
9. `has_stone_pickaxe` (bool): Tiene pico de piedra
10. `has_iron_pickaxe` (bool): Tiene pico de hierro

### Espacio de Acciones
**12 acciones** (id√©nticas a TODAS las etapas):
```python
actions = [
    "move 1", "move -1",           # 0, 1: Adelante/atr√°s
    "strafe 1", "strafe -1",       # 2, 3: Izquierda/derecha
    "turn 1", "turn -1",           # 4, 5: Girar
    "pitch 0.1", "pitch -0.1",     # 6, 7: Mirar arriba/abajo
    "attack 1",                    # 8: Atacar/minar
    "craft_wooden_pickaxe",        # 9: Stage 1 craft
    "craft_stone_pickaxe",         # 10: Stage 2 craft
    "craft_iron_pickaxe"           # 11: Stage 3 craft
]
```

**TODOS los craft actions se usan en este agente.**

### Selecci√≥n Autom√°tica de Herramientas
**Hardcoded** (no aprendido) - Prioridad jer√°rquica:
- `diamond_ore` ‚Üí Selecciona `iron_pickaxe`
- `iron_ore` ‚Üí Selecciona `stone_pickaxe`
- `stone` ‚Üí Selecciona `wooden_pickaxe`
- `log` ‚Üí Selecciona `diamond_axe`

### Crafting Jer√°rquico
**Auto-crafting de componentes** (como wood_agent y iron_agent):

#### Wooden Pickaxe
```
Si wood >= 3:
  1. Craftear planks desde wood (1 wood = 4 planks)
  2. Craftear sticks desde planks (2 planks = 4 sticks)
  3. Craftear wooden_pickaxe (3 planks + 2 sticks)
```

#### Stone Pickaxe
```
Si stone >= 3 AND has_wooden_pickaxe:
  1. Craftear sticks si es necesario
  2. Craftear stone_pickaxe (3 stone + 2 sticks)
```

#### Iron Pickaxe
```
Si iron >= 3 AND has_stone_pickaxe:
  1. Craftear sticks si es necesario
  2. Craftear iron_pickaxe (3 iron + 2 sticks)
```

### Sistema de Recompensas
```xml
<RewardForCollectingItem>
    <Item reward="1000" type="log"/>
    <Item reward="2000" type="stone"/>
    <Item reward="5000" type="iron_ore"/>
    <Item reward="5000" type="iron_ingot"/>
    <Item reward="100000" type="diamond"/>  ‚Üê RECOMPENSA MASIVA
</RewardForCollectingItem>

<RewardForTouchingBlockType>
    <Block reward="-1" type="lava"/>
    <Block reward="-100" type="obsidian"/>
</RewardForTouchingBlockType>
```

**Nota**: Recompensa por diamond es 100,000 (el doble de Stage 4) debido a la complejidad.

## Transfer Learning
El agente carga por defecto el modelo entrenado de **Stage 4 (Diamond)**:
```
../entrenamiento_acumulado/{algorithm}_diamond_model.pkl
```

### Pipeline Completo de Transfer Learning
```
Stage 1 (Wood)     ‚Üí  wood_model.pkl
      ‚Üì
Stage 2 (Stone)    ‚Üí  stone_model.pkl
      ‚Üì
Stage 3 (Iron)     ‚Üí  iron_model.pkl
      ‚Üì
Stage 4 (Diamond)  ‚Üí  diamond_model.pkl
      ‚Üì
Stage 5 (Scratch)  ‚Üí  scratch_model.pkl  ‚Üê ESTA ETAPA
```

### ¬øQu√© se transfiere?
- ‚úÖ **Pol√≠ticas de movimiento**: Exploraci√≥n eficiente
- ‚úÖ **Pol√≠ticas de minado**: Atacar bloques correctamente
- ‚úÖ **Pol√≠ticas de navegaci√≥n**: Evitar obst√°culos
- ‚úÖ **Pol√≠ticas de crafting**: Preferencias de craft actions
- ‚úÖ **Q-values**: Conocimiento acumulado de 4 etapas previas

## Uso

### Entrenamiento Individual
```bash
cd desde_cero

# Con transfer learning (RECOMENDADO)
python from_scratch_agent.py --algorithm qlearning --episodes 50

# Desde cero (NO RECOMENDADO - muy dif√≠cil)
python from_scratch_agent.py --algorithm qlearning --episodes 50 --load-model none

# Con puerto personalizado
python from_scratch_agent.py --algorithm sarsa --episodes 50 --port 10002
```

### Entrenamiento Paralelo (6 algoritmos simult√°neos)
```bash
cd desde_cero
python run_parallel_experiments.py
```
**Puertos utilizados**: 10001-10006

**‚ö†Ô∏è ADVERTENCIA**: Este es el experimento m√°s largo (5 minutos por episodio √ó 50 episodios √ó 6 algoritmos = ~25 horas si fueran secuenciales, ~4 horas en paralelo)

### An√°lisis de Resultados
```bash
cd desde_cero
python analyze_results.py
```

## Archivos Generados

### Modelos
```
../entrenamiento_acumulado/
‚îú‚îÄ‚îÄ qlearning_scratch_model.pkl
‚îú‚îÄ‚îÄ sarsa_scratch_model.pkl
‚îú‚îÄ‚îÄ expected_sarsa_scratch_model.pkl
‚îú‚îÄ‚îÄ double_q_scratch_model.pkl
‚îú‚îÄ‚îÄ monte_carlo_scratch_model.pkl
‚îî‚îÄ‚îÄ random_scratch_model.pkl
```

### M√©tricas
```
metrics_data/
‚îú‚îÄ‚îÄ qlearning_FromScratchAgent_{timestamp}.csv
‚îú‚îÄ‚îÄ qlearning_FromScratchAgent_{timestamp}.png
‚îî‚îÄ‚îÄ ... (para cada algoritmo)
```

### Logs (modo paralelo)
```
resultados/
‚îú‚îÄ‚îÄ qlearning_scratch_log.txt
‚îú‚îÄ‚îÄ sarsa_scratch_log.txt
‚îî‚îÄ‚îÄ ... (para cada algoritmo)
```

## Pipeline Completo de Entrenamiento

### Secuencia Completa (TODOS los 5 Stages)
```bash
# Stage 1: Wood (sin transfer learning)
cd madera
python wood_agent.py --algorithm qlearning --episodes 50

# Stage 2: Stone (carga wood_model.pkl)
cd ../piedra
python stone_agent.py --algorithm qlearning --episodes 50 \
    --load-model ../entrenamiento_acumulado/qlearning_model.pkl

# Stage 3: Iron (carga stone_model.pkl)
cd ../hierro
python iron_agent.py --algorithm qlearning --episodes 50 \
    --load-model ../entrenamiento_acumulado/qlearning_stone_model.pkl

# Stage 4: Diamond (carga iron_model.pkl)
cd ../diamante
python diamond_agent.py --algorithm qlearning --episodes 50 \
    --load-model ../entrenamiento_acumulado/qlearning_iron_model.pkl

# Stage 5: From Scratch (carga diamond_model.pkl) ‚Üê ESTA ETAPA
cd ../desde_cero
python from_scratch_agent.py --algorithm qlearning --episodes 50 \
    --load-model ../entrenamiento_acumulado/qlearning_diamond_model.pkl
```

## M√©tricas Recolectadas
- **total_reward**: Recompensa acumulada (puede ser MUY alta)
- **steps**: N√∫mero de pasos por episodio (hasta 15,000)
- **epsilon**: Valor de exploraci√≥n (Œµ)
- **success**: Si se complet√≥ el tech tree (obtuvo diamond)
- **diamond_collected**: Cantidad de diamante recolectado (objetivo: 1)
- **max_diamond**: M√°ximo diamante en inventario
- **iron_collected**: Hierro recolectado
- **max_iron**: M√°ximo hierro en inventario
- **stone_collected**: Stone recolectado
- **max_stone**: M√°ximo stone en inventario
- **wood_collected**: Wood recolectado
- **max_wood**: M√°ximo wood en inventario
- **action_distribution**: Distribuci√≥n de acciones ejecutadas

## Diferencias con Otros Stages

### vs Stage 4 (Diamond)
1. **Inventario inicial**: Solo diamond_axe (vs 6 items)
2. **Crafting**: Requiere 3 craft actions (vs 0)
3. **Etapas**: Debe completar 4 sub-objetivos (vs 1)
4. **Tiempo**: 300 segundos (vs 120)
5. **Recursos**: Todos los recursos presentes (vs solo diamond/iron/stone)
6. **Complejidad**: M√ÅXIMA - requiere secuencia completa

### vs Stage 1 (Wood)
1. **Objetivo**: Diamond (vs wooden_pickaxe)
2. **Profundidad**: 4 etapas (vs 1)
3. **Transfer learning**: Carga diamond_model (vs entrenar desde cero)
4. **Recompensa**: 100,000 por diamond (vs objetivo impl√≠cito)

## Desaf√≠os T√©cnicos
1. **Largo horizonte temporal**: Hasta 15,000 pasos por episodio
2. **Sparse rewards**: Recompensas espaciadas (wood ‚Üí stone ‚Üí iron ‚Üí diamond)
3. **Dependencias secuenciales**: No puedes minar diamond sin iron_pickaxe
4. **Espacio de estados grande**: Combinaci√≥n de todos los recursos
5. **Decisiones multi-etapa**: Requiere planificaci√≥n a largo plazo

## Verificaci√≥n de Transfer Learning

### Prueba de Eficacia
Para verificar que el transfer learning funciona:

```bash
# 1. Entrenar CON transfer learning
python from_scratch_agent.py --algorithm qlearning --episodes 50 \
    --load-model ../entrenamiento_acumulado/qlearning_diamond_model.pkl

# 2. Entrenar SIN transfer learning
python from_scratch_agent.py --algorithm qlearning --episodes 50

# 3. Comparar m√©tricas:
#    - Episodios hasta primer √©xito
#    - Recompensa promedio
#    - Tasa de √©xito
```

**Expectativa**: El agente con transfer learning deber√≠a:
- ‚úÖ Lograr el primer √©xito m√°s r√°pido
- ‚úÖ Tener mayor recompensa promedio
- ‚úÖ Mayor tasa de √©xito final

## Interpretaci√≥n de Resultados

### √âxito Parcial
El agente puede tener √©xito parcial:
- ‚úÖ Crafted wooden_pickaxe (Stage 1 completo)
- ‚úÖ Crafted stone_pickaxe (Stage 2 completo)
- ‚ùå No crafted iron_pickaxe (Stage 3 incompleto)
- ‚ùå No diamond (Stage 4 incompleto)

### √âxito Completo
```
Wood: 3+ ‚Üí Wooden Pick ‚úì ‚Üí Stone: 3+ ‚Üí Stone Pick ‚úì ‚Üí 
Iron: 3+ ‚Üí Iron Pick ‚úì ‚Üí Diamond: 1 ‚úì
```

## Conclusi√≥n
**Stage 5** es la demostraci√≥n final de que el aprendizaje jer√°rquico funciona. Un agente que comienza casi vac√≠o puede completar un tech tree complejo gracias al conocimiento transferido de las 4 etapas anteriores.

Este es el **test definitivo** del sistema de transfer learning implementado.
