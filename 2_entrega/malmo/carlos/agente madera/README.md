# Agente RL - RecolecciÃ³n de Madera en Minecraft

Este agente de Aprendizaje por Refuerzo (Q-Learning) aprende a buscar, picar y recolectar madera en Minecraft usando Malmo.

## ğŸ¯ Objetivo

El agente debe:
1. **Buscar** Ã¡rboles en el mundo
2. **Acercarse** a los bloques de madera
3. **Picar** el bloque hasta romperlo
4. **Recoger** el drop acercÃ¡ndose al item para agregarlo al inventario

## ğŸ“‹ Requisitos

- Minecraft 1.11.2
- Malmo instalado y configurado
- Python 3.x
- Bibliotecas: numpy, matplotlib, pickle

## ğŸš€ Uso

### Entrenar el agente

```bash
python mundo_rl.py
```

El entrenamiento ejecutarÃ¡ 50 episodios por defecto. Cada episodio:
- Dura mÃ¡ximo 120 segundos o 800 pasos
- El agente spawn en posiciones aleatorias
- Termina cuando obtiene madera o se acaba el tiempo

### ParÃ¡metros configurables

En `mundo_rl.py` puedes modificar:

```python
NUM_EPISODIOS = 50        # Cantidad de episodios
MODELO_PATH = "modelo_agente_madera.pkl"  # Archivo del modelo
```

En `agente_rl.py` puedes ajustar hiperparÃ¡metros:

```python
agente = AgenteQLearning(
    alpha=0.1,           # Tasa de aprendizaje
    gamma=0.95,          # Factor de descuento
    epsilon=0.4,         # ExploraciÃ³n inicial
    epsilon_decay=0.995  # Decaimiento de exploraciÃ³n
)
```

## ğŸ“Š AnÃ¡lisis de Resultados

El archivo `utils.py` proporciona herramientas para analizar el entrenamiento:

```bash
# Ver resumen del entrenamiento
python utils.py resumen

# Graficar evoluciÃ³n del aprendizaje
python utils.py graficar

# Analizar tabla Q aprendida
python utils.py analizar

# Exportar polÃ­tica a archivo de texto
python utils.py exportar

# Ejecutar todos los anÃ¡lisis
python utils.py todo
```

## ğŸ® Acciones Disponibles

El agente puede ejecutar 5 acciones:

1. `move 1` - Avanzar hacia adelante
2. `turn 1` - Girar 90Â° a la derecha
3. `turn -1` - Girar 90Â° a la izquierda
4. `jumpmove 1` - Saltar y avanzar (para superar obstÃ¡culos)
5. `attack 1` - Picar bloque (mantiene presionado para romper)

## ğŸ§  RepresentaciÃ³n del Estado

El estado se discretiza en una tupla de 9 elementos:

```python
(orientaciÃ³n, madera_cerca, madera_frente, distancia_madera,
 obstaculo_frente, aire_frente, tiene_madera, altura, mirando_madera)
```

Donde:
- **orientaciÃ³n**: 0=Norte, 1=Este, 2=Sur, 3=Oeste
- **madera_cerca**: 1 si detecta madera en rejilla 5x3x5, 0 si no
- **madera_frente**: 1 si hay madera justo enfrente, 0 si no
- **distancia_madera**: 0=muy cerca (puede picar), 1=cerca, 2=lejos, 3=no visible
- **obstaculo_frente**: 1 si hay obstÃ¡culo sÃ³lido, 0 si no
- **aire_frente**: 1 si hay aire enfrente, 0 si no
- **tiene_madera**: 1 si ya tiene madera en inventario, 0 si no
- **altura**: 0=bajo (<60), 1=medio (60-70), 2=alto (>70)
- **mirando_madera**: 1 si LineOfSight apunta a madera, 0 si no

## ğŸ’° Sistema de Recompensas

### Recompensas Positivas
- **+200**: Obtener madera en inventario (OBJETIVO)
- **+50**: Picar bloque exitosamente (de Malmo)
- **+30**: Picar cuando hay madera enfrente
- **+20**: Detectar madera muy cerca
- **+15**: Acercarse a madera visible
- **+5**: Intentar moverse despuÃ©s de girar
- **+3**: Movimiento exitoso
- **+2**: Mirar hacia madera

### Penalizaciones
- **-0.5**: Costo por cada acciÃ³n
- **-5**: ColisiÃ³n con obstÃ¡culo
- **-10**: Picar sin madera enfrente
- **-15**: Alejarse de madera una vez detectada
- **-20**: Loop de giros detectado
- **-30**: Atascado completamente (>8 pasos sin movimiento)

## ğŸ”§ CaracterÃ­sticas Especiales

### Sistema Anti-Stuck
Si el agente se queda atascado sin moverse por mÃ¡s de 12 pasos:
- Ejecuta secuencia de escape: girar y saltar
- Resetea contador despuÃ©s de la secuencia

### HeurÃ­stica de Picado
Si el agente ve madera enfrente y estÃ¡ mirÃ¡ndola:
- AutomÃ¡ticamente ejecuta `attack` para picar
- Mantiene el comando por 0.5 segundos
- Realiza 3 ataques consecutivos (necesario en Minecraft 1.11.2)

### Tipos de Madera Detectados
El agente reconoce todas las variantes de madera:
- `log` - Roble, abedul, abeto, jungla
- `log2` - Acacia, roble oscuro
- `planks` - Tablas (por si acaso)

## ğŸ“ˆ Progreso Esperado

### Primeros 10 episodios
- Alta exploraciÃ³n (epsilon ~0.4)
- Aprendiendo movimientos bÃ¡sicos
- Descubriendo el entorno

### Episodios 10-30
- ReducciÃ³n de exploraciÃ³n
- Comenzando a reconocer Ã¡rboles
- Primeros intentos de picar

### Episodios 30-50
- Comportamiento mÃ¡s dirigido
- Mayor tasa de Ã©xito
- OptimizaciÃ³n de pasos

## ğŸ”„ PrÃ³ximos Pasos

Este agente es el primer paso de una secuencia progresiva:

1. **Madera** âœ… (actual)
2. **Piedra** (siguiente)
3. **Hierro** (futuro)
4. **Diamante** (objetivo final)

Cada etapa construye sobre la anterior, incrementando la complejidad de la tarea.

## ğŸ› Troubleshooting

### El agente no encuentra Ã¡rboles
- AsegÃºrate de que el mundo generado tenga Ã¡rboles (bioma adecuado)
- Aumenta el nÃºmero de episodios para mejor exploraciÃ³n
- Ajusta `spawn_x` y `spawn_z` para aparecer cerca de bosques

### El agente pica pero no recoge la madera
- Verifica que los items droppeados no desaparezcan (check game rules)
- El agente debe estar cerca del item para recogerlo automÃ¡ticamente
- Revisa que no haya obstÃ¡culos entre el agente y el drop

### Bajo rendimiento de aprendizaje
- Aumenta `alpha` (tasa de aprendizaje) a 0.15-0.2
- Reduce `epsilon_decay` para mantener mÃ¡s exploraciÃ³n
- Incrementa `NUM_EPISODIOS` a 100+

### Errores de conexiÃ³n con Malmo
- Verifica que Minecraft estÃ© corriendo con Malmo en puerto 10001
- Comprueba que no haya otras instancias del agente corriendo
- Reinicia Minecraft si hay problemas persistentes

## ğŸ“ Notas

- El modelo se guarda automÃ¡ticamente cada 10 episodios
- Puedes interrumpir el entrenamiento con Ctrl+C y el progreso se guardarÃ¡
- La tabla Q se carga automÃ¡ticamente al reiniciar el entrenamiento
- Los archivos generados: `modelo_agente_madera.pkl`, `analisis_entrenamiento_madera.png`

## ğŸ‘¨â€ğŸ’» Autor

Sistema de IA - Seminario 1 Proyecto
