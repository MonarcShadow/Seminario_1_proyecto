# ğŸ“‹ Resumen TÃ©cnico - Sistema de RecolecciÃ³n de Madera

## ğŸ¯ Objetivo del Sistema

Entrenar un agente de aprendizaje por refuerzo (Q-Learning) para **recolectar 3 bloques de madera** picando Ã¡rboles en Minecraft usando Project Malmo.

---

## ğŸ”‘ Diferencias Clave con el Sistema de BÃºsqueda de Agua

| CaracterÃ­stica | Sistema Agua (Jonathan) | Sistema Madera (Carlos) |
|---------------|------------------------|-------------------------|
| **Objetivo** | Tocar agua | Picar y recolectar 3 maderas |
| **Acciones** | 4 (move, turnÃ—2, jumpmove) | 7 (+attack, strafeÃ—2) |
| **Estado** | 6 dimensiones | 7 dimensiones |
| **Grid** | 5Ã—3Ã—5 (75 bloques) | 5Ã—5Ã—5 (125 bloques) |
| **Inventario** | No usado | âœ“ Tracking activo |
| **Raycast** | BÃ¡sico | âœ“ DetecciÃ³n de distancia |
| **Recompensa mÃ¡xima** | +100 (tocar agua) | +500 (3 maderas) |
| **Criterio Ã©xito** | RewardForTouchingBlock | Inventario â‰¥ 3 |
| **Tiempo lÃ­mite** | 60 seg | 120 seg |
| **Epsilon inicial** | 0.3 | 0.4 |

---

## ğŸ§  Arquitectura del Estado

### Estado del Agente (7 dimensiones)

```python
estado = (
    orientacion,        # int [0-3]: Norte, Este, Sur, Oeste
    nivel_madera,       # int [0-2]: Cantidad de madera visible
    nivel_inventario,   # int [0-3]: Maderas en inventario (0, 1, 2, 3+)
    mirando_madera,     # bool [0-1]: Â¿Mira directamente a madera?
    dist_categoria,     # int [0-2]: Distancia al bloque (cerca/medio/lejos)
    obstaculo_frente,   # bool [0-1]: Â¿Hay obstÃ¡culo?
    indicador_hojas     # int [0-2]: Nivel de hojas (seÃ±al de Ã¡rbol)
)
```

**TamaÃ±o del espacio de estados**: 4 Ã— 3 Ã— 4 Ã— 2 Ã— 3 Ã— 2 Ã— 3 = **864 estados posibles**

---

## âš™ï¸ Acciones Disponibles

```python
ACCIONES = {
    0: "move 1",        # Avanzar 1 bloque
    1: "turn 1",        # Girar derecha 90Â°
    2: "turn -1",       # Girar izquierda 90Â°
    3: "jumpmove 1",    # Saltar + avanzar
    4: "attack 1",      # ğŸ†• Picar/Atacar (mantener)
    5: "strafe 1",      # ğŸ†• Moverse lateral derecha
    6: "strafe -1",     # ğŸ†• Moverse lateral izquierda
}
```

### Nueva acciÃ³n clave: `attack 1`
- **DuraciÃ³n**: 0.6 segundos (tiempo de picado)
- **Uso**: Romper bloques de madera
- **Recompensa condicionada**: +30 si mira madera, -5 si no

---

## ğŸ’° Sistema de Recompensas

### Recompensas Positivas

| Evento | Valor | Trigger |
|--------|-------|---------|
| ğŸ† **Completar objetivo** | **+500** | Inventario â‰¥ 3 maderas |
| ğŸªµ **Conseguir 1 madera** | **+100** | Item en inventario (Malmo) |
| ğŸª“ **Picar madera** | **+30** | attack + mirando madera |
| ğŸ” **Picar consistente** | **+10** | Picar mismo bloque |
| ğŸ‘ï¸ **Mirar madera cerca** | **+20** | Raycast madera < 3m |
| ğŸ‘ï¸ **Mirar madera lejos** | **+10** | Raycast madera 3-5m |
| ğŸŒ³ **Madera en grid** | **+10** | Detectada en percepciÃ³n |
| ğŸƒ **Hojas abundantes** | **+5** | >5 hojas = Ã¡rbol cerca |
| ğŸš¶ **Moverse exitoso** | **+3** | Cambio de posiciÃ³n real |

### Recompensas Negativas

| Evento | Valor | Trigger |
|--------|-------|---------|
| âš¡ **Costo acciÃ³n** | **-0.5** | Cada comando (Malmo) |
| âŒ **Picar aire** | **-5** | attack sin mirar madera |
| ğŸš§ **ColisiÃ³n repetida** | **-10** | 5+ pasos sin movimiento |
| ğŸ”„ **Loop de giros** | **-20** | 6 giros consecutivos |
| ğŸ”„ **Loop de ataques** | **-25** | 6 ataques sin madera |
| ğŸ›‘ **Atascado total** | **-30** | >10 pasos sin movimiento |

---

## ğŸ“Š Observaciones del Entorno

### ObservationFromGrid (5Ã—5Ã—5)
```xml
<Grid name="near5x5x5">
  <min x="-2" y="-2" z="-2"/>
  <max x="2" y="2" z="2"/>
</Grid>
```
- **Total**: 125 bloques
- **Uso**: DetecciÃ³n de madera, hojas, obstÃ¡culos

### ObservationFromRay
```json
{
  "type": "log",        // Tipo de bloque mirando
  "distance": 2.5       // Distancia en bloques
}
```
- **Uso**: PrecisiÃ³n para picar

### ObservationFromFullInventory
```json
{
  "inventory": [
    {"type": "wooden_axe", "quantity": 1, "slot": 0},
    {"type": "log", "quantity": 2}
  ]
}
```
- **Uso**: Tracking de madera recolectada

---

## ğŸ”§ HiperparÃ¡metros Q-Learning

```python
alpha = 0.15          # Tasa de aprendizaje (â†‘ del 0.1)
gamma = 0.95          # Factor de descuento
epsilon = 0.4         # ExploraciÃ³n inicial (â†‘ del 0.3)
epsilon_min = 0.05    # MÃ­nimo epsilon
epsilon_decay = 0.995 # Decaimiento por episodio
```

### JustificaciÃ³n de cambios:
- **Alpha mÃ¡s alto**: Entorno mÃ¡s complejo (picar vs tocar)
- **Epsilon mÃ¡s alto**: MÃ¡s exploraciÃ³n necesaria (buscar Y picar)

---

## ğŸ® ConfiguraciÃ³n XML Malmo

### Mundo
```xml
<DefaultWorldGenerator seed="42" forceReset="false"/>
```
- **Seed fija (42)**: Reproducibilidad
- **forceReset=false**: Reutilizar mundo (mÃ¡s rÃ¡pido)

### Inventario Inicial
```xml
<Inventory>
  <InventoryItem slot="0" type="wooden_axe"/>
</Inventory>
```
- **Hacha de madera** en primer slot de hotbar
- Permite picar madera

### LÃ­mites de Tiempo
```xml
<ServerQuitFromTimeUp timeLimitMs="120000"/>
```
- **2 minutos** por episodio (vs 1 minuto en agua)
- MÃ¡s tiempo para buscar + picar

### CondiciÃ³n de Salida
```xml
<AgentQuitFromCollectingItem>
  <Item type="log" amount="3"/>
</AgentQuitFromCollectingItem>
```
- Termina automÃ¡ticamente al conseguir 3 maderas

---

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### Durante Entrenamiento
- **Tasa de Ã©xito**: % episodios con 3+ maderas
- **Madera promedio**: Maderas por episodio
- **Pasos promedio**: Eficiencia temporal
- **Recompensa acumulada**: Tendencia de aprendizaje

### GrÃ¡ficos Generados (utils_madera.py)
1. **Recompensas** + media mÃ³vil (ventana 5)
2. **Madera recolectada** (barra: verde=Ã©xito, rojo=fallo)
3. **Pasos por episodio** + eficiencia
4. **Epsilon decay** (exploraciÃ³n vs explotaciÃ³n)

---

## ğŸ”„ Flujo de Entrenamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. INICIAR EPISODIO                            â”‚
â”‚     - Reset entorno                             â”‚
â”‚     - Spawn con hacha                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. BUCLE DE DECISIÃ“N (max 800 pasos)           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ a) Observar: grid + raycast + inv    â”‚   â”‚
â”‚     â”‚ b) Discretizar estado                â”‚   â”‚
â”‚     â”‚ c) Elegir acciÃ³n (Îµ-greedy)          â”‚   â”‚
â”‚     â”‚ d) Ejecutar comando                  â”‚   â”‚
â”‚     â”‚ e) Capturar recompensa Malmo         â”‚   â”‚
â”‚     â”‚ f) Calcular recompensa total         â”‚   â”‚
â”‚     â”‚ g) Actualizar Q(s,a)                 â”‚   â”‚
â”‚     â”‚ h) Verificar inventario â‰¥ 3          â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â†“ (si no completado)                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. FINALIZAR EPISODIO                          â”‚
â”‚     - Guardar estadÃ­sticas                      â”‚
â”‚     - Decaer epsilon                            â”‚
â”‚     - Guardar modelo (cada 5 episodios)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ ExtensiÃ³n a Otros Materiales

### Piedra (Siguiente Fase)
```python
# Cambios necesarios:
TIPOS_OBJETIVO = ["stone", "cobblestone"]
HERRAMIENTA_INICIAL = "wooden_pickaxe"
CANTIDAD_OBJETIVO = 5  # bloques
```

### Hierro
```python
TIPOS_OBJETIVO = ["iron_ore"]
HERRAMIENTA_INICIAL = "stone_pickaxe"
ESTADO += (nivel_y_categoria,)  # Buscar en profundidad
```

### Diamante
```python
TIPOS_OBJETIVO = ["diamond_ore"]
HERRAMIENTA_INICIAL = "iron_pickaxe"
RESTRICCION_Y = "y < 16"  # Solo capas profundas
```

---

## ğŸ› Mecanismos Anti-Stuck

### DetecciÃ³n de Loops
```python
# Loop de giros (sin moverse)
if ultimas_6_acciones.todas("turn") and sin_movimiento > 3:
    recompensa -= 20
```

### Sistema de Escape
```python
if pasos_sin_movimiento > 10:
    forzar_secuencia([
        "turn 1",      # Girar 90Â°
        "turn 1",      # Girar 90Â° mÃ¡s (180Â° total)
        "jumpmove 1"   # Saltar hacia adelante
    ])
```

---

## ğŸ“¦ Archivos del Proyecto

```
carlos/
â”œâ”€â”€ mundo2v2.py                 # â­ Script principal
â”œâ”€â”€ agente_madera_rl.py         # Algoritmo Q-Learning
â”œâ”€â”€ entorno_madera.py           # Wrapper Malmo + recompensas
â”œâ”€â”€ utils_madera.py             # VisualizaciÃ³n y anÃ¡lisis
â”œâ”€â”€ configurar.py               # Setup automÃ¡tico
â”œâ”€â”€ test_sistema_madera.py      # Tests unitarios
â”œâ”€â”€ README_MADERA.md            # DocumentaciÃ³n completa
â”œâ”€â”€ RESUMEN_TECNICO.md          # Este archivo
â””â”€â”€ modelo_agente_madera.pkl    # (generado al entrenar)
```

---

## ğŸ“ Referencias TÃ©cnicas

- **Algoritmo**: Q-Learning (Watkins & Dayan, 1992)
- **Entorno**: Project Malmo (Microsoft Research)
- **Juego**: Minecraft 1.11.2
- **Python**: 3.7+
- **LibrerÃ­as**: NumPy, Matplotlib, Pickle

---

## âœ… Checklist de Uso

- [ ] Malmo instalado y configurado
- [ ] Minecraft 1.11.2 corriendo (puerto 10000)
- [ ] Dependencias Python instaladas
- [ ] Verificar con: `python configurar.py`
- [ ] Entrenar: `python mundo2v2.py`
- [ ] Visualizar: `python utils_madera.py graficar`
- [ ] Analizar: `python utils_madera.py analizar`

---

**Ãšltima actualizaciÃ³n**: 2 de noviembre de 2025  
**Autor**: Sistema de IA  
**Proyecto**: Seminario 1 - Aprendizaje por Refuerzo en Minecraft
