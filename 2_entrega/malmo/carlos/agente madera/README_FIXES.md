# Agente RL - BÃºsqueda y RecolecciÃ³n de Madera

## ğŸ¯ Objetivo
Agente de aprendizaje por refuerzo (Q-Learning) que aprende a buscar, encontrar y recolectar madera en Minecraft usando Malmo.

## ğŸ“ Archivos principales

### Scripts de entrenamiento
- **`entrenar_normal.py`**: Entrenamiento en mundo normal (DefaultWorldGenerator)
- **`entrenar_plano.py`**: Entrenamiento en mundo plano (para pruebas)
- **`test_movimiento.py`**: VerificaciÃ³n bÃ¡sica de comandos de movimiento
- **`debug_movimiento.py`**: Debug detallado del sistema de movimiento

### MÃ³dulos principales
- **`agente_rl.py`**: ImplementaciÃ³n del agente Q-Learning
- **`entorno_malmo.py`**: Wrapper del entorno de Malmo, sistema de recompensas
- **`mundo_rl.py`**: ConfiguraciÃ³n del mundo XML y loop de entrenamiento
- **`utils.py`**: Utilidades para anÃ¡lisis y visualizaciÃ³n

## ğŸš€ Uso

### Entrenamiento en mundo normal (recomendado)
```bash
malmoenv  # Activar entorno virtual
cd "agente madera"
python3 entrenar_normal.py 50  # 50 episodios
```

### Pruebas en mundo plano
```bash
python3 entrenar_plano.py 10  # 10 episodios de prueba
```

### Verificar movimiento bÃ¡sico
```bash
python3 test_movimiento.py
```

## ğŸ”§ Correcciones aplicadas (Nov 2025)

### Problema: Agente no se movÃ­a
**SÃ­ntomas**: PosiciÃ³n fija, sistema anti-stuck activÃ¡ndose constantemente

**Causas identificadas**:
1. âœ… DuraciÃ³n de comandos muy lenta (0.5s â†’ 0.1s)
2. âœ… CÃ¡lculo de distancia en 3D incluÃ­a Y (saltos contaban como no-movimiento)
3. âœ… Thresholds anti-stuck muy altos (18 â†’ 10)
4. âœ… LÃ³gica de penalizaciones incorrecta (aplicaba siempre en vez de solo cuando no se movÃ­a)
5. âœ… Spawn aleatorio colocaba agente en posiciones invÃ¡lidas
6. âœ… CondiciÃ³n `AgentQuitFromReachingPosition` terminaba misiÃ³n inmediatamente

**Soluciones aplicadas**:

#### 1. DuraciÃ³n de comandos (entorno_malmo.py)
```python
# Antes: duracion=0.5 (muy lento)
def ejecutar_accion(self, comando, duracion=0.5):

# DespuÃ©s: duracion=0.1 (igual que agente agua)
def ejecutar_accion(self, comando, duracion=0.1):
```

#### 2. Distancia en 2D (entorno_malmo.py)
```python
# Antes: Distancia 3D (incluÃ­a Y)
distancia = ((dx)**2 + (dy)**2 + (dz)**2)**0.5

# DespuÃ©s: Distancia 2D (solo X,Z - ignora saltos)
distancia = ((posicion_actual[0] - self.posicion_previa[0])**2 + 
            (posicion_actual[2] - self.posicion_previa[2])**2)**0.5
```

#### 3. Thresholds anti-stuck (mundo_rl.py)
```python
# Antes: Muy tolerante, permitÃ­a demasiado tiempo sin movimiento
if entorno.pasos_sin_movimiento > 18:

# DespuÃ©s: MÃ¡s estricto, igual que agente agua
if entorno.pasos_sin_movimiento > 10:
```

#### 4. LÃ³gica de penalizaciones (entorno_malmo.py)
```python
# Antes: Historial y penalizaciones SIEMPRE
if distancia > 0.3:
    recompensa += 3.0
else:
    self.pasos_sin_movimiento += 1

self.historial_acciones.append(accion)  # âŒ Siempre
if self.pasos_sin_movimiento > 3:      # âŒ Penaliza incluso si se moviÃ³
    recompensa -= ...

# DespuÃ©s: Historial y penalizaciones SOLO cuando NO se mueve
if distancia > 0.3:
    recompensa += 3.0
    self.pasos_sin_movimiento = 0
else:
    self.pasos_sin_movimiento += 1
    self.historial_acciones.append(accion)  # âœ… Solo si no se moviÃ³
    if self.pasos_sin_movimiento > 3:       # âœ… Solo penaliza sin movimiento
        recompensa -= ...
```

#### 5. Spawn fijo (mundo_rl.py, entrenar_plano.py)
```python
# Antes: Spawn aleatorio (mundo plano puede tener agua/bloques)
spawn_x = random.uniform(-150, 150)
spawn_z = random.uniform(-150, 150)

# DespuÃ©s: Spawn natural del mundo (seguro)
spawn_x = None  # Mundo normal: spawn natural
spawn_z = None

# O spawn fijo para mundo plano:
spawn_x = 0.5
spawn_z = 0.5
```

#### 6. Condiciones de salida (mundo_rl.py)
```python
# Removido: CondiciÃ³n problemÃ¡tica que terminaba misiÃ³n inmediatamente
# <AgentQuitFromReachingPosition>
#   <Marker x="0" y="20" z="0" tolerance="50.0"/>
# </AgentQuitFromReachingPosition>

# Mantenido: Solo terminar al colectar madera
<AgentQuitFromCollectingItem>
  <Item type="log" />
  <Item type="log2" />
</AgentQuitFromCollectingItem>
```

## ğŸ“Š Resultados despuÃ©s de correcciones

### Antes
- Pasos: 0-108
- PosiciÃ³n: **FIJA** (46.0, 4.0, 23.6)
- Comportamiento: Solo saltaba en el mismo lugar
- Recompensa: -3527.00

### DespuÃ©s
- Pasos: 106+
- PosiciÃ³n: **CAMBIANDO** (0.5â†’22.5â†’54.5â†’84.5â†’114.5)
- Comportamiento: Se mueve correctamente, explora
- Recompensa: +35.00

## ğŸ® Acciones disponibles

1. **`move 1`**: Avanzar 1 bloque
2. **`turn 1`**: Girar 90Â° a la derecha
3. **`turn -1`**: Girar 90Â° a la izquierda
4. **`jumpmove 1`**: Saltar y avanzar
5. **`attack 1`**: Picar bloque (mantiene presionado)

## ğŸ§  Estado discretizado (9 dimensiones)

1. **orientacion**: 0-3 (N, E, S, O)
2. **madera_cerca**: 0-1 (hay madera en grid 5x3x5)
3. **madera_frente**: 0-1 (hay madera justo enfrente)
4. **distancia_madera**: 0-3 (muy cerca, cerca, lejos, no visible)
5. **obstaculo_frente**: 0-1 (bloque sÃ³lido enfrente)
6. **tiene_madera**: 0-1 (madera en inventario)
7. **altura_relativa**: 0-2 (bajo, medio, alto)
8. **aire_frente**: 0-1 (aire enfrente)
9. **mirando_madera**: 0-1 (LineOfSight ve madera)

## ğŸ Sistema de recompensas

| Evento | Recompensa |
|--------|-----------|
| Colectar madera (Malmo) | +50.0 |
| Moverse exitosamente | +3.0 |
| Comando enviado | -0.5 |
| Sin movimiento (progresiva) | -2.0 * pasos |
| Loop de giros | -20.0 |
| Completamente atascado (>8 pasos) | -30.0 |
| Picar sin madera enfrente | -10.0 |

## ğŸ” Debugging

Si el agente no se mueve:
1. Ejecutar `python3 debug_movimiento.py` para verificar comandos
2. Revisar que `duracion=0.1` en `ejecutar_accion()`
3. Verificar que distancia se calcula solo en 2D (X,Z)
4. Confirmar que spawn no es aleatorio problemÃ¡tico
5. Revisar logs de Malmo para errores

## ğŸ“ˆ ComparaciÃ³n con agente de agua

El agente de madera estÃ¡ basado en el agente de agua (que funciona correctamente).
Diferencias principales:
- âœ… **Acciones**: Madera tiene 5 (incluye `attack`), Agua tiene 4
- âœ… **Estado**: Madera 9D, Agua 5D
- âœ… **DuraciÃ³n**: Ambos usan 0.1s
- âœ… **Distancia**: Ambos usan 2D (X,Z)
- âœ… **Thresholds**: Ambos usan 3 y 8 pasos
- âœ… **Penalizaciones**: Misma lÃ³gica (solo cuando no se mueve)

## ğŸš§ PrÃ³ximos pasos

1. âœ… Agente se mueve correctamente
2. ğŸ”„ Entrenar en mundo normal con Ã¡rboles
3. ğŸ”„ Optimizar heurÃ­stica de picar madera
4. ğŸ”„ Ajustar parÃ¡metros de aprendizaje (alpha, gamma, epsilon)
5. ğŸ“‹ Implementar agente de piedra
6. ğŸ“‹ Implementar agente de hierro
7. ğŸ“‹ Implementar agente de diamante

## ğŸ“ Notas tÃ©cnicas

- Minecraft versiÃ³n: 1.11.2
- Malmo: 0.37.0
- Python: 3.6.15
- Puerto: 10001 (hardcoded)
- Semilla por defecto: 123456
