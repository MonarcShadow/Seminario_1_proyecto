# ü™ì Agente de Recolecci√≥n de Madera - Gu√≠a de Uso

## üìã Descripci√≥n
Agente de Q-Learning que aprende a recolectar madera en Minecraft usando Malmo.

**Objetivo**: Obtener 2+ bloques de madera (log/oak_wood) O 8+ tablas de madera (planks)

---

## üöÄ ENTRENAMIENTO EXHAUSTIVO

### 1Ô∏è‚É£ Entrenamiento en Mundo Normal (Recomendado)

```bash
# Entrenamiento exhaustivo (50+ episodios)
python3 entrenar_normal.py 50

# Entrenamiento largo (100 episodios)
python3 entrenar_normal.py 100

# Continuar entrenamiento (a√±ade 30 episodios m√°s)
python3 entrenar_normal.py 30
```

**Caracter√≠sticas**:
- Mundo natural con terreno generado proceduralmente
- √Årboles distribuidos naturalmente
- El modelo se guarda cada 10 episodios
- Archivo generado: `modelo_agente_madera.pkl`

### 2Ô∏è‚É£ Entrenamiento en Mundo Plano (Solo para pruebas)

```bash
# Pruebas r√°pidas (10 episodios)
python3 entrenar_plano.py 10

# M√°s episodios de prueba
python3 entrenar_plano.py 25
```

**Caracter√≠sticas**:
- Mundo plano sin obst√°culos naturales
- √ötil para verificar que el agente se mueve correctamente
- Archivo generado: `modelo_agente_madera_plano.pkl`

---

## üéÆ EJECUTAR MODELO ENTRENADO

Una vez completado el entrenamiento, ejecuta el modelo sin exploraci√≥n aleatoria:

### Ejecuci√≥n en Mundo Normal

```bash
# 5 episodios (default)
python3 ejecutar_modelo.py

# 10 episodios
python3 ejecutar_modelo.py 10

# 20 episodios
python3 ejecutar_modelo.py 20
```

### Ejecuci√≥n en Mundo Plano

```bash
# 3 episodios en mundo plano
python3 ejecutar_modelo.py 3 plano

# 5 episodios en mundo plano
python3 ejecutar_modelo.py 5 plano
```

**Diferencia con entrenamiento**:
- ‚úÖ `epsilon = 0` (sin exploraci√≥n aleatoria)
- ‚úÖ El agente solo usa lo que aprendi√≥
- ‚úÖ Permite evaluar el rendimiento real del modelo

---

## üìä Archivos Generados

| Archivo | Descripci√≥n |
|---------|-------------|
| `modelo_agente_madera.pkl` | Modelo entrenado en mundo normal |
| `modelo_agente_madera_plano.pkl` | Modelo entrenado en mundo plano |

---

## üîÑ Flujo de Trabajo Recomendado

### Paso 1: Verificar que funciona
```bash
python3 entrenar_plano.py 5
```
Verifica que el agente se mueve y no hay errores.

### Paso 2: Entrenamiento exhaustivo
```bash
python3 entrenar_normal.py 50
```
Deja que entrene 50+ episodios (puede tomar tiempo).

### Paso 3: Evaluar el modelo
```bash
python3 ejecutar_modelo.py 10
```
Observa cu√°ntos episodios completa exitosamente.

### Paso 4 (Opcional): M√°s entrenamiento
Si la tasa de √©xito es baja (<20%), entrena m√°s:
```bash
python3 entrenar_normal.py 50  # A√±ade 50 episodios m√°s
```

---

## üéØ Sistema de Recompensas

El agente aprende mediante:

| Acci√≥n | Recompensa |
|--------|-----------|
| üå≤ Picar madera | +30 |
| üçÉ Picar hojas | +1 |
| üì¶ Recoger item droppeado | +10 a +40 |
| üéØ Madera muy cerca | +20 |
| üîç Madera detectada | +5 |
| üçÉ Hojas detectadas | +5 |
| üö∂ Moverse correctamente | +3 |
| üëÄ Mirar hacia madera | +2 |
| ‚ùå Picar sin madera | -10 |
| ‚ö†Ô∏è Alejarse de madera | -15 |
| üò¥ Holgazanear cerca de √°rboles | -5 √ó pasos |
| üîÑ Loop de giros | -20 |
| üö´ Atascado | -30 |

---

## üìà Interpretaci√≥n de Resultados

Durante el entrenamiento ver√°s:

```
üìä Resumen Episodio #1
   Pasos: 291
   √âxito: ‚úó
   Recompensa total: -132.00
   Tasa de √©xito: 0/1 (0.0%)
```

**Indicadores de progreso**:
- ‚úÖ Recompensa total aumenta con el tiempo
- ‚úÖ Tasa de √©xito mejora gradualmente
- ‚úÖ El agente pica madera m√°s frecuentemente
- ‚ö†Ô∏è Si la recompensa se mantiene negativa, puede necesitar m√°s entrenamiento

---

## üõ†Ô∏è Soluci√≥n de Problemas

### El agente no se mueve
```bash
# Verifica manualmente que funciona
python3 test_movimiento.py
```

### Errores de Malmo
- Aseg√∫rate de que Minecraft con Malmo est√© ejecut√°ndose
- Verifica el archivo `.config` con IP y puerto correctos
- Puerto default: 10001

### Entrenamiento muy lento
- Normal: cada episodio toma 1-3 minutos
- Puedes interrumpir con `Ctrl+C`, el progreso se guarda autom√°ticamente

---

## üí° Tips

1. **Paciencia**: Los primeros 10-20 episodios suelen ser exploratorios
2. **Guardado autom√°tico**: El modelo se guarda cada 10 episodios
3. **Continuaci√≥n**: Puedes ejecutar `entrenar_normal.py` m√∫ltiples veces, contin√∫a desde donde qued√≥
4. **Epsilon decay**: La exploraci√≥n disminuye autom√°ticamente con el tiempo

---

## üìû Comandos R√°pidos

```bash
# Entrenamiento exhaustivo
python3 entrenar_normal.py 50

# Ejecutar modelo entrenado
python3 ejecutar_modelo.py 10

# Verificar funcionamiento
python3 entrenar_plano.py 5
```

¬°Buena suerte entrenando tu agente! üöÄü™ì
