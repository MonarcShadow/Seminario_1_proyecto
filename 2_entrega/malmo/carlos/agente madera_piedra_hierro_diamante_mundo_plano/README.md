# Agente RL Progresivo Multi-Material

Agente de Aprendizaje por Refuerzo que progresa a travÃ©s de mÃºltiples objetivos en Minecraft:
**Madera â†’ Piedra â†’ Hierro â†’ Diamante**

## ðŸŽ¯ Objetivos del Agente

El agente debe completar las siguientes fases en orden:

### Fase 0: ðŸŒ² MADERA
- **Objetivo:** Recolectar 3 bloques de madera
- **Herramienta:** Ninguna (mano)
- **MÃ©todo:** Picar troncos de Ã¡rboles

### Fase 1: ðŸª¨ PIEDRA  
- **Objetivo:** Recolectar 3 bloques de piedra
- **Herramienta:** Pico de madera (proporcionado al inicio)
- **MÃ©todo:** Picar bloques de piedra/cobblestone
- **Crafteo simulado:** Al completar, recibe pico de piedra

### Fase 2: âš™ï¸ HIERRO
- **Objetivo:** Recolectar 3 lingotes de hierro
- **Herramienta:** Pico de piedra
- **MÃ©todo:** Picar menas de hierro (conversiÃ³n automÃ¡tica a lingote)
- **Crafteo simulado:** Al completar, recibe pico de hierro

### Fase 3: ðŸ’Ž DIAMANTE (Final)
- **Objetivo:** Recolectar 1 diamante
- **Herramienta:** Pico de hierro
- **MÃ©todo:** Picar mena de diamante
- **Â¡Ã‰xito!** Objetivo final completado

## ðŸ—ºï¸ Entorno Controlado

### CaracterÃ­sticas del Mundo Plano

- **TamaÃ±o:** 50Ã—50 bloques
- **Spawn:** Centro (0, 4, 0)
- **PerÃ­metro:** Muro de obsidiana (altura 6 bloques)
- **Suelo:** Piedra

### DistribuciÃ³n de Materiales

Todos los materiales se generan aleatoriamente dentro del Ã¡rea:

- **ðŸŒ² Madera:** 15-20 ubicaciones (troncos oak/spruce)
- **ðŸª¨ Piedra:** 15-20 ubicaciones (stone/cobblestone)
- **âš™ï¸ Hierro:** 8-12 ubicaciones (iron_ore)
- **ðŸ’Ž Diamante:** 3-5 ubicaciones (diamond_ore)

Algunos materiales se colocan en torres de 1-3 bloques de altura para requerir cambios de pitch.

## ðŸ§  Sistema de Aprendizaje

### Algoritmo: Q-Learning Modular

- **Q-tables separadas por fase** (mejor especializaciÃ³n)
- **ParÃ¡metros adaptativos** segÃºn complejidad de fase
- **Estado:** 12 dimensiones
  - OrientaciÃ³n (0-3: N, E, S, O)
  - Material cerca (bool)
  - Material frente (bool)
  - Distancia a material (0-2)
  - ObstÃ¡culo frente (bool)
  - Aire frente (bool)
  - Tiene suficiente material (bool)
  - Altura relativa (0-2)
  - Mirando material (bool)
  - Ãngulo vertical (0-2: abajo, frente, arriba)
  - Fase actual (0-3)
  - Herramienta correcta (bool)

### Acciones (7 total)

```python
0: move 1        # Avanzar
1: turn 1        # Girar derecha
2: turn -1       # Girar izquierda
3: jumpmove 1    # Saltar + avanzar
4: attack 1      # Picar
5: pitch 1       # Mirar arriba
6: pitch -1      # Mirar abajo
```

### Sistema de Recompensas

Las recompensas escalan segÃºn la fase (mÃ¡s difÃ­cil = mayor recompensa):

#### Recompensas Positivas
- **+200-500:** Obtener material objetivo (Ã—fase)
- **+30-100:** Picar material correcto
- **+20-50:** Estar muy cerca del objetivo
- **+10-25:** Estar cerca del objetivo
- **+5-10:** Movimiento efectivo hacia objetivo
- **+8-15:** Usar pitch cerca de objetivo

#### Castigos Negativos
- **-30 a -100:** Atacar sin herramienta correcta (no drop)
- **-30 a -50:** Atacar sin objetivo frente
- **-10 a -20:** Buscar material de fase anterior
- **-5Ã—N:** Holgazanear cerca sin picar (N pasos - 8)
- **-1:** Quedarse atascado sin movimiento

### ParÃ¡metros Adaptativos por Fase

```python
Fase 0 (MADERA):   Î±=0.10, Îµ=0.40, mult=1.0
Fase 1 (PIEDRA):   Î±=0.12, Îµ=0.35, mult=1.2
Fase 2 (HIERRO):   Î±=0.15, Îµ=0.30, mult=1.5
Fase 3 (DIAMANTE): Î±=0.20, Îµ=0.25, mult=2.0
```

## ðŸ“¦ Estructura del Proyecto

```
agente madera_piedra_hierro_diamante_mundo_plano/
â”œâ”€â”€ agente_rl.py          # Agente Q-Learning modular
â”œâ”€â”€ entorno_malmo.py      # Entorno con recompensas por fase
â”œâ”€â”€ mundo_rl.py           # Generador de mundo + loop entrenamiento
â”œâ”€â”€ utils.py              # Utilidades
â”œâ”€â”€ README.md             # Este archivo
â””â”€â”€ modelo_progresivo.pkl # Modelo entrenado (se genera)
```

## ðŸš€ Uso

### Requisitos Previos

1. **Minecraft 1.11.2** corriendo con Malmo
2. **Malmo 0.37.0** instalado
3. **Python 3.6+** con MalmoPython

### âš ï¸ IMPORTANTE: ConfiguraciÃ³n del Cliente

Si Minecraft estÃ¡ en otra mÃ¡quina (ejemplo: Windows), edita `config.py`:

```python
MINECRAFT_HOST = "192.168.1.100"  # IP de la mÃ¡quina con Minecraft
MINECRAFT_PORT = 10001
```

Para encontrar la IP en Windows: `ipconfig` en CMD

Ver guÃ­a completa en: **[CONEXION_CLIENTE.md](CONEXION_CLIENTE.md)**

### Verificar ConexiÃ³n

```bash
# Probar que el cliente estÃ¡ disponible
python3 config.py

# O usar test completo
python3 test_sistema.py
```

### Entrenamiento

```bash
# Entrenar 100 episodios con semilla fija
python3 mundo_rl.py 100 123456

# Entrenar 50 episodios con otra semilla
python3 mundo_rl.py 50 999888

# Por defecto (100 episodios, semilla 123456)
python3 mundo_rl.py
```

### ParÃ¡metros

- **Argumento 1:** NÃºmero de episodios (default: 100)
- **Argumento 2:** Semilla para mundo (default: 123456)

### Durante el Entrenamiento

El programa muestra:
- ðŸ—ºï¸ GeneraciÃ³n del mundo (cantidad de materiales)
- ðŸŽ® Progreso en tiempo real cada 50 pasos
- ðŸ“Š Resumen al final de cada episodio
- ðŸ’¾ Guardado de modelo cada 10 episodios

### Ejemplo de Salida

```
================================================================
ðŸ—ºï¸  MUNDO PLANO GENERADO
================================================================
Ãrea: 50x50 bloques
Spawn: (0, 4, 0)

Materiales colocados:
  ðŸŒ² Madera:   18 ubicaciones (23 bloques)
  ðŸª¨ Piedra:   17 ubicaciones (21 bloques)
  âš™ï¸  Hierro:   10 ubicaciones (14 bloques)
  ðŸ’Ž Diamante: 4 ubicaciones (5 bloques)

Semilla: 123456
================================================================

ðŸŒ² +1 MADERA obtenida! (Total: 1/3) [+200.0]
ðŸŒ² +1 MADERA obtenida! (Total: 2/3) [+200.0]
ðŸŒ² +1 MADERA obtenida! (Total: 3/3) [+200.0]

============================================================
ðŸŒ² FASE MADERA COMPLETADA!
   Madera recolectada: 3/3
   â†’ Avanzando a fase PIEDRA
============================================================

ðŸª¨ +1 PIEDRA obtenida! (Total: 1/3) [+250.0]
...
```

## ðŸŽ“ Simplificaciones del Proyecto

Para facilitar el entrenamiento, se implementaron estas simplificaciones:

1. **Inventario limpiado** al inicio (evitar items de episodios anteriores)
2. **Pico de madera inicial** dado por comando `/give`
3. **Crafteo simulado:** Al completar fase, se da herramienta siguiente automÃ¡ticamente
4. **ConversiÃ³n hierro:** Iron_ore â†’ iron_ingot automÃ¡tica (sin horno)
5. **Mundo plano controlado:** Todos los materiales cerca (50Ã—50 Ã¡rea)

## âš ï¸ Consideraciones

### Castigos por Herramienta Incorrecta

El agente aprende que:
- Picar piedra sin pico de madera â†’ no drop â†’ castigo
- Picar hierro sin pico de piedra â†’ no drop â†’ castigo  
- Picar diamante sin pico de hierro â†’ no drop â†’ castigo

### ProgresiÃ³n Obligatoria

El agente **debe** completar las fases en orden:
- No puede saltar fases
- Atacar materiales de fase anterior da castigo
- Cada fase desbloquea la siguiente

### Timeout

- MÃ¡ximo 1000 pasos por episodio (~5 minutos)
- Si no completa, episodio falla

## ðŸ“Š MÃ©tricas de Ã‰xito

Para considerar el entrenamiento exitoso:

- **Tasa de Ã©xito >70%** en Ãºltimos 20 episodios
- **Fase 3 alcanzada** consistentemente
- **Recompensa media >1000** en Ãºltimos episodios
- **Pasos medio <500** (eficiencia)

## ðŸ”§ Ajuste de HiperparÃ¡metros

Si el agente no aprende bien, ajustar en `agente_rl.py`:

```python
# Aumentar exploraciÃ³n inicial
epsilon=0.5  # default: 0.4

# Reducir decaimiento (explorar mÃ¡s tiempo)
epsilon_decay=0.998  # default: 0.995

# Aumentar aprendizaje
alpha=0.15  # default: 0.1

# Ajustar descuento (balance inmediato vs futuro)
gamma=0.98  # default: 0.95
```

## ðŸ“ Archivos Generados

- `modelo_progresivo.pkl` - Modelo entrenado (Q-tables + parÃ¡metros)
- Logs en consola con progreso detallado

## ðŸ› Troubleshooting

### Agente se queda atascado
- Sistema anti-stuck a los 15 pasos sin movimiento
- Fuerza turn + jumpmove para escapar

### No encuentra materiales
- Verificar que el mundo se generÃ³ correctamente
- Probar con diferente semilla
- Aumentar nÃºmero de materiales en `generar_mundo_plano_xml()`

### Ataca sin herramienta correcta
- Normal en primeros episodios (exploraciÃ³n)
- Debe aprender con el castigo fuerte
- Si persiste, aumentar castigo en `entorno_malmo.py`

## ðŸŽ¯ PrÃ³ximos Pasos

Una vez funcionando en mundo plano:
1. Probar en mundo normal (DefaultWorldGenerator)
2. Reducir cantidad de materiales (mÃ¡s realista)
3. Ampliar Ã¡rea de bÃºsqueda
4. Agregar mÃ¡s objetivos (carbÃ³n, redstone, etc.)

---

**Autor:** Sistema de IA  
**Fecha:** Noviembre 2025  
**VersiÃ³n:** 1.0
